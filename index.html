---
layout: page
tagline:
---

{% for post in paginator.posts %}

<article class="home">

  <span class="post-date">
    {% assign d = post.date | date: "%d" | plus:'0' %}
    {{ post.date | date: "%B" }}
    {% case d %}
    {% when 1 or 21 or 31 %}{{ d }}st,
    {% when 2 or 22 %}{{ d }}nd,
    {% when 3 or 23 %}{{ d }}rd,
    {% else %}{{ d }}th,
    {% endcase %}
    {{ post.date | date: "%Y" }}
  </span>

  <h2>
    <a href="{{ site.BASE_PATH }}{{ post.url }}">{{ post.title }}</a>
  </h2>

  <div>
    {% if post.fullview %}
    {{ post.content }}
    {% else %}
    {% if post.shortinfo %}
    {{ post.shortinfo }}
    {% elsif post.description %}
    {{ post.description }}
    {% else %}
    {{ post.excerpt }}
    {% endif %}
    {% endif %}
  </div>

</article>
{% endfor %}
<div class="Bio">
    <header>
        <h1 margin="0px"><i class="fa fa-paperclip"></i> Biography</h1>
    </header>
    <p>
    I am currently an Associate Professor in School of Electronic Engineering at Xidian University. Before that I obtained my PhD degree in School of Electronic Engineering, Xidian University,
	    under the supervision of Prof. <a href="http://see.xidian.edu.cn/faculty/chdeng/">Cheng Deng</a>. I received the bachelor degree in Xidian University in July, 2016. 

	    
    </p>
</div>

<div class="Research Interests">
    <header>
        <h1><i class="fa fa-fire"></i> Research Interests</h1>
    </header>
    <p>
    Deep Learning, Graph Representation Learning, and Clustering
    </p>
</div>
<div class="Achademic Services">
    <header>
        <h1><i class="fa fa-fire"></i> Achademic Serves</h1>
    </header>
	<p>
    Executive Area Chair of Vision And Learning SEminar (VALSE)
    </p>
    <p>
    Programme committee (PC) member for CVPR, NeurIPS, ICML, AAAI, IJCAI
    </p>
	<p>
    Senior programme committee (SPC) member for IJCAI 2021
    </p>
</div>

<div class="News">
    <header>
        <h1><i class="fa fa-bolt"></i> News</h1>
    </header>


	<p>
    <i class="fa fa-bolt"></i>
    Jul. 1, 2025, three papers were accepted to IJCAI2025.
    </p>	
	<p>
    <i class="fa fa-bolt"></i>
    Jul. 1, 2025, one paper was accepted to IEEE TIP.
    </p>	
	<p>
    <i class="fa fa-bolt"></i>
    Feb. 1, 2025, one paper was accepted to WACV2025.
    </p>
	<p>
    <i class="fa fa-bolt"></i>
    Jul. 1, 2024, three papers were accepted to IEEE TIP, TCSVT, and TMM, respectively.
    </p>
	<p>
    <i class="fa fa-bolt"></i>
    Apr. 18, 2024, one paper was accepted to IJCAI2024.
    </p>
	
	<p>
    <i class="fa fa-bolt"></i>
    Mar. 29, 2024, three papers were accepted to CVPR2024.
    </p>
	<p>
    <i class="fa fa-bolt"></i>
    Mar. 24, 2024, one paper was accepted to IEEE TKDE.
    </p>

	<p>
    <i class="fa fa-bolt"></i>
    Dec. 09, 2023, one paper was accepted to AAAI2024 (23% acceptance rate).
    </p>

	<p>
    <i class="fa fa-bolt"></i>
    Nov. 20, 2023, one paper was accepted to IEEE TCYB.
    </p>	
	<p>
    <i class="fa fa-bolt"></i>
	I was selected for the Shaanxi Association for Science and Technology Youth Lifting Talent Program.
    </p>	
	<p>
    <i class="fa fa-bolt"></i>
    Apr. 20, 2023, one paper was accepted to IJCAI2023 (15% acceptance rate).
    </p>
	<p>
    <i class="fa fa-bolt"></i>
    Apr. 19, 2023, three papers were accepted to IEEE TNNLS, TMM.
    </p>
	<p>
    <i class="fa fa-bolt"></i>
    Apr. 21, 2022, one paper was accepted to IJCAI2022.
    </p>
	<p>
    <i class="fa fa-bolt"></i>
    Mar. 8, 2022, one paper was accepted to IEEE TIP.
    </p>
	<p>
    <i class="fa fa-bolt"></i>
    Mar. 2, 2022, two papers were accepted to CVPR2022 (25.3% acceptance rate).
    </p>
	<p>
    <i class="fa fa-bolt"></i>
    I was elected as the Executive Area Chair (EAC) of the sixth VALSE.
    </p>
    </div>

<div class="Publications">
    <header>
        <h1><i class="fa fa-file"></i> Publications [<a href="https://scholar.google.com/citations?view_op=list_works&hl=en&authuser=1&user=Uc3piAIAAAAJ" target="_blank">Google Scholar</a>]</h1>
    </header>
    <p><font size="4"><strong>Under Review</strong></font></p>
    <ol>

		    <li>
            <p>
                <strong>	
Mix‑QSAM2: Mixed‑Precision Quantization for High Fidelity Segmentation in Resource Constrained Scenarios</strong><br>
               Under Review
            </p>
        </li>	
				    <li>
            <p>
                <strong>	
UniCRep: Learning Unified Circuit Representations via Function-Structure Decoupling and Task-Aware Adaptive Fusion</strong><br>
               Under Review
            </p>
        </li>
				    <li>
            <p>
                <strong>	
Towards Robust Edge Model Adaptation via Elastic Architecture Search</strong><br>
               Under Review
            </p>
        </li>
		            <p>
                <strong>	
Trajectory Regularized: Reducing Storage Dependency in Model Merging for Continual Learning</strong><br>
               Under Review
            </p>
        </li>	
    </ol>

	
	
    <p><font size="4"><strong>Journal Articles</strong></font></p>
    <ol>
	    <li>
            <p>
                <strong>Robust Commonsense Reasoning Against Noisy Labels Using Adaptive Correction</strong><br>
		<em><strong>X. Yang</strong></em>, C. Deng, K. Wei and D. Tao<br>
               IEEE Trans. Cybern., 2024.(IF<sub>20</sub>=19.118)
            </p>
        </li>	
	    <li>
            <p>
                <strong>Unsupervised Structure-Adaptive Graph Contrastive Learning</strong><br>
		H. Zhao, <em><strong>X. Yang</strong></em>, C. Deng, D. Tao<br>
               IEEE Trans. Neural Netw. Learn. Syst., 2023.(IF<sub>20</sub>=10.451)
            </p>
        </li>	
	    	<li>
            <p>
                <strong>Dual-Stream Contrastive Learning for Compositional Zero-Shot Recognition</strong><br>
		Y. Yang, R. Pan, X. Li, <em><strong>X. Yang</strong></em>, C. Deng<br>
               IEEE Trans. Multimed., 2023.(IF<sub>20</sub>=8.182)
            </p>
        </li>	
	    <li>
            <p>
                <strong>Point-Supervised Video Temporal Grounding</strong><br>
		Z. Xu, K. Wei, <em><strong>X. Yang</strong></em>, C. Deng<br>
               IEEE Trans. Multimed., 2022.(IF<sub>20</sub>=8.182)
            </p>
        </li>
	    	    <li>
            <p>
                <strong>Object-Agnostic Transformers for Video Referring Segmentation</strong><br>
                 <em><strong>X. Yang</strong></em>, H. Wang, D. Xie, C. Deng, and D. Tao<br>
               IEEE Trans. Image Process., 2022.(IF<sub>20</sub>=10.856)
            </p>
        </li>
	    	    <li>
            <p>
                <strong>Incremental Zero-Shot Learning</strong><br>
                 K. Wei, C. Deng, <em><strong>X. Yang</strong></em>, and D. Tao<br>
               IEEE Trans. Cybern., 2021.(IF<sub>20</sub>=11.448)
            </p>
        </li>
	    	    <li>
            <p>
                <strong>Self-Training with Progressive Representation Enhancement for Unsupervised Cross-Domain Person Re-identification</strong><br>
                 H. Zhang, H. Cao, <em><strong>X. Yang</strong></em>, C. Deng and D. Tao<br>
               IEEE Trans. Image Process., 30: 5287-5298, 2021.(IF<sub>20</sub>=10.856)
            </p>
        </li>
	    	    <li>
            <p>
                <strong>Deep Multi-View Collaborative Clustering </strong><br>
                 <em><strong>X. Yang</strong></em>, C. Deng, Z. Dang, and D. Tao<br>
               IEEE Trans. Neural Netw. Learn. Syst., 2021.(IF<sub>20</sub>=10.451)
            </p>
        </li>
	    
	    <li>
            <p>
                <strong>Heterogeneous Graph Attention Network for Unsupervised Multiple-Target Domain Adaptation</strong><br>
                 <em><strong>X. Yang</strong></em>, C. Deng, T. Liu, and D. Tao<br>
               IEEE Trans. Pattern Anal. Mach. Intell., 2020. (IF<sub>20</sub>=16.389)
            </p>
        </li>
	    <li>
            <p>
                <strong>Saliency Detection via a Multiple Self-Weighted Graph-Based Manifold Ranking</strong><br>
                 C. Deng, <em><strong>X. Yang</strong></em>, F. Nie, and D. Tao<br>
               IEEE Trans. Multimed., 2019. (IF<sub>20</sub>=6.513)
            </p>
        </li>
    </ol>
    <p><font size="4"><strong>Conference Proceedings</strong></font></p>
    <ol>
	    <li><p><strong>New L21-Norm Relaxation of Multi-Way Graph Cut for Clustering </strong><br>
            <em><strong>X. Yang</strong></em>, C. Deng, X. Liu, and F. Nie<br>
 In AAAI Conference on Artificial Intelligence (<em><strong>AAAI</strong></em>), 2018.
            </p>
        </li>
	    <li><p><strong>Deep Spectral Clustering Using Dual Autoencoder Network[<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Yang_Deep_Spectral_Clustering_Using_Dual_Autoencoder_Network_CVPR_2019_paper.pdf">Paper</a>][<a href="https://github.com/xdxuyang/Deep-Spectral-Clustering-using-Dual-Autoencoder-Network">Code</a>]</strong><br>
            <em><strong>X. Yang</strong></em>, C. Deng, F. Zheng, J. Yan, and W. Liu<br>
 In IEEE International Conference on Pattern Recognition and Computer Vision (<em><strong>CVPR</strong></em>), 2019.
            </p>
        </li>	    
	    <li><p><strong>Multi-Scale Fusion Subspace Clustering Using Similarity Constraint</strong><br>
            Z. Dang, C. Deng, <em><strong>X. Yang</strong></em>, H. Huang<br>
 In IEEE International Conference on Pattern Recognition and Computer Vision (<em><strong>CVPR</strong></em>), 2020.
            </p>
        </li>		        
	    <li><p><strong>Lifelong Zero-shot Learning</strong><br>
            K. Wei, C. Deng, <em><strong>X. Yang</strong></em><br>
 In International Joint Conference on Artificial Intelligence (<em><strong>IJCAI</strong></em>), 2020.
            </p>
        </li>		    
	    <li><p><strong>Adversarial Learning for Robust Deep Clustering</strong><br>
            <em><strong>X. Yang</strong></em>, C. Deng, K. Wei, J. Yan, and W. Liu<br>
In Thirty-fourth Conference on Neural Information Processing Systems (<em><strong>NeurIPS</strong></em>), 2020.
            </p>
        </li>		    
	    <li><p><strong>Incremental Embedding Learning via Zero-Shot Translation</strong><br>
            K. Wei, C. Deng, <em><strong>X. Yang</strong></em> and M. Li<br>
In AAAI Conference on Artificial Intelligence (<em><strong>AAAI</strong></em>), 2021.
            </p>
        </li>		    
	    <li><p><strong>SelfSAGCN: Self-Supervised Semantic Alignment for Graph Convolution Network[<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_SelfSAGCN_Self-Supervised_Semantic_Alignment_for_Graph_Convolution_Network_CVPR_2021_paper.html">Paper</a>][<a href="https://github.com/xdxuyang/SelfSAGCN">Code</a>]</strong><br>
            <em><strong>X. Yang</strong></em>, C. Deng, Z. Dang, K. Wei, and J. Yan<br>
 In IEEE International Conference on Pattern Recognition and Computer Vision (<em><strong>CVPR</strong></em>), 2021.
            </p>
        </li>		    
	    <li><p><strong>Nearest Neighbor Matching for Deep Clustering</strong><br>
            Z. Dang, C. Deng, <em><strong>X. Yang</strong></em>, K. Wei, H. Huang<br>
 In IEEE International Conference on Pattern Recognition and Computer Vision (<em><strong>CVPR</strong></em>), 2021.
            </p>
        </li>			    
	    <li><p><strong>Graph Debiased Contrastive Learning with Joint Representation Clustering[<a href="https://github.com/hzhao98/GDCL">Code</a>]</strong><br>
            H. Zhao, <em><strong>X. Yang</strong></em>, Z. Wang, E. Yang, and C. Deng<br>
 In 30th International Joint Conference on Artificial Intelligence (<em><strong>IJCAI</strong></em>), 2021.
            </p>
        </li>
	    <li><p><strong>Learning Universal Adversarial Perturbation by Adversarial Example</strong><br>
            M. Li, Y. Yang, K. Wei, <em><strong>X. Yang</strong></em>, and H. Huang<br> 
 In AAAI Conference on Artificial Intelligence (<em><strong>AAAI</strong></em>), 2022.
            </p>
        </li>
	    <li><p><strong>Not Just Selection, but Exploration: Online Class-Incremental Continual Learning via Dual View Consistency</strong><br>
            Y. Gu, <em><strong>X. Yang</strong></em>, K. Wei, and C. Deng<br> 
 In IEEE/CVF Conference on Computer Vision and Pattern Recognition (<em><strong>CVPR</strong></em>), 2022.
            </p>
        </li>
	    <li><p><strong>Siamese Contrastive Embedding Network for Compositional Zero-Shot Learning</strong><br>
            X. Li, <em><strong>X. Yang</strong></em>, K. Wei, C. Deng, and M. Yang<br> 
 In IEEE/CVF Conference on Computer Vision and Pattern Recognition (<em><strong>CVPR</strong></em>), 2022.
            </p>
        </li>
	   <li><p><strong>Attention-guided Contrastive Hashing for Long-tailed Image Retrieval</strong><br>
            X. Kou, C. Xu, <em><strong>X. Yang</strong></em> and C. Deng <br>
 In 31th International Joint Conference on Artificial Intelligence (<em><strong>IJCAI</strong></em>), 2022.
            </p>
        </li>
	<li><p><strong>Exploring Safety Supervision for Continual Test-time Domain Adaptation</strong><br>
            <em><strong>X. Yang</strong></em>, Y. Ya, K. Wei and C. Deng <br>
 In 32th International Joint Conference on Artificial Intelligence (<em><strong>IJCAI</strong></em>), 2023.
            </p>
        </li>
	<li><p><strong>Dynamic Reactive Spiking Graph Neural Network</strong><br>
            H. Zhao, <em><strong>X. Yang</strong></em>, C. Deng, and J. Yan <br>
 In Thirty-Eighth AAAI Conference on Artificial Intelligence (<em><strong>AAAI</strong></em>), 2024.
            </p>
        </li>
	<li><p><strong>Unveiling the Unknown: Unleashing the Power of Unknown to Known in Open-Set Source-Free Domain Adaptation</strong><br>
            F. Wan, H. Zhao, <em><strong>X. Yang</strong></em>, and C. Deng <br>
 In IEEE/CVF Conference on Computer Vision and Pattern Recognition (<em><strong>CVPR</strong></em>), 2024.
            </p>
        </li>  
	<li><p><strong>Long-Tail Class Incremental Learning via Independent Sub-prototype Construction</strong><br>
            X. Wang, <em><strong>X. Yang</strong></em>, J. Yin, K. Wei and C. Deng <br>
 In IEEE/CVF Conference on Computer Vision and Pattern Recognition (<em><strong>CVPR</strong></em>), 2024.
            </p>
        </li>  
	<li><p><strong>A Versatile Framework for Continual Test-Time Domain Adaptation: Balancing Discriminability and Generalizability</strong><br>
            <em><strong>X. Yang</strong></em>, X. Chen, M. Li, K. Wei and C. Deng <br>
 In IEEE/CVF Conference on Computer Vision and Pattern Recognition (<em><strong>CVPR</strong></em>), 2024.
            </p>
        </li> 

    </ol>
    
</div>
 <a href='https://www.symptoma.ro/'>www.Symptoma.ro</a> <script type='text/javascript' src='https://www.freevisitorcounters.com/auth.php?id=6229873a2f13744d57ad01394aa1b42c8cfd39a8'></script>
<script type="text/javascript" src="https://www.freevisitorcounters.com/en/home/counter/496026/t/0"></script>
</div>
